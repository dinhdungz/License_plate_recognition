{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bycpPBajm8lz",
        "outputId": "300baafb-f263-45ea-f8e9-f5ada3a113fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting vidgear\n",
            "  Downloading vidgear-0.3.0-py3-none-any.whl (114 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/114.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from vidgear) (0.29.36)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vidgear) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vidgear) (2.27.1)\n",
            "Collecting colorlog (from vidgear)\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from vidgear) (4.65.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vidgear) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vidgear) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->vidgear) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vidgear) (2.10)\n",
            "Installing collected packages: colorlog, vidgear\n",
            "Successfully installed colorlog-6.7.0 vidgear-0.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install vidgear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "us68SccNyqHC"
      },
      "outputs": [],
      "source": [
        "# Import library\n",
        "import torch\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import math\n",
        "import functools\n",
        "from vidgear.gears import WriteGear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9G6JPR_y-Ia",
        "outputId": "e0235de0-edb9-425d-cf6c-1aa8fce2b469"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 15814, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 15814 (delta 10), reused 25 (delta 2), pack-reused 15768\u001b[K\n",
            "Receiving objects: 100% (15814/15814), 14.64 MiB | 30.29 MiB/s, done.\n",
            "Resolving deltas: 100% (10819/10819), done.\n",
            "/content/yolov5\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m605.5/605.5 kB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.6/55.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt # install dependencies\n",
        "%pip install -q roboflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8tYvQcMsCC9",
        "outputId": "141be266-1d01-41f1-a475-7698d05aace1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-19 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/usr/local/lib/python3.10/dist-packages/cycler-0.11.0.dist-info/METADATA'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fusing layers... \n",
            "Model summary: 157 layers, 7091035 parameters, 0 gradients, 16.0 GFLOPs\n",
            "Adding AutoShape... \n",
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "YOLOv5 🚀 2023-7-19 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/usr/local/lib/python3.10/dist-packages/idna-3.4.dist-info/METADATA'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        }
      ],
      "source": [
        "# Load model\n",
        "character_recognition = torch.hub.load('ultralytics/yolov5', 'custom', path = './Weight/character_recognition.pt')\n",
        "plate_detection = torch.hub.load('ultralytics/yolov5', 'custom', path = './Weight/plate_detection.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "A-CQqFe5mULA"
      },
      "outputs": [],
      "source": [
        "def compare(rect1, rect2):\n",
        "    if abs(rect1[1] - rect2[1]) > 20:\n",
        "        return rect1[1] - rect2[1]\n",
        "    else:\n",
        "        return rect1[0] - rect2[0]\n",
        "\n",
        "def linearEquation(p1, p2):\n",
        "    if p1[0] == p2[0]:\n",
        "        p1[0] = p2[0] + 1\n",
        "\n",
        "    a = (p1[1] - p2[1]) / (p1[0] - p2[0])\n",
        "    b = p1[1] - a * p1[0]\n",
        "    return a, b\n",
        "\n",
        "def rotateByAngle(image, angle):\n",
        "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "    rotation_matrix = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "    result = cv2.warpAffine(image, rotation_matrix, image.shape[1::-1])\n",
        "    return result\n",
        "\n",
        "def rotateImage(image):\n",
        "    edges_image = cv2.Canny(image,  threshold1 = 100,  threshold2 = 200, apertureSize = 3, L2gradient = True)\n",
        "    lines = cv2.HoughLinesP(edges_image, 1, math.pi/180, threshold=40, minLineLength=image.shape[1]/2.6, maxLineGap=image.shape[1]/25)\n",
        "\n",
        "    if lines is not None:\n",
        "        list_angle = []\n",
        "        for [[x1, y1, x2, y2]] in lines:\n",
        "            a, b = linearEquation([x1, y1], [x2, y2])\n",
        "            if a > 0:\n",
        "                angle = math.atan(a) / math.pi * 180\n",
        "            else:\n",
        "                angle = -math.atan(-a) / math.pi * 180\n",
        "            if abs(angle) <= 45:\n",
        "                list_angle.append(angle)\n",
        "\n",
        "        if not list_angle:\n",
        "            return image\n",
        "\n",
        "        angle = sum(list_angle) / len(list_angle)\n",
        "        image = rotateByAngle(image, angle)\n",
        "\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XhMUA5k7j2u",
        "outputId": "b7e8414d-2721-434f-a0e9-d72b67ab130d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Can't receive frame (stream end?). Exiting ...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "cap = cv2.VideoCapture('./test.mp4')\n",
        "out = WriteGear(output= './Output.mp4')\n",
        "\n",
        "while cap.isOpened():\n",
        "  ret, frame = cap.read()\n",
        "  if not ret:\n",
        "    print(\"Can't receive frame (stream end?). Exiting ...\")\n",
        "    break\n",
        "\n",
        "  detection = plate_detection(frame)\n",
        "  detect_results = detection.pandas().xyxy[0].to_numpy()\n",
        "\n",
        "  for i in detect_results:\n",
        "        if i[4] >= 0.6:\n",
        "            x_min = int(i[0])\n",
        "            x_max = int(i[2])\n",
        "            y_min = int(i[1])\n",
        "            y_max = int(i[3])\n",
        "\n",
        "            img = frame[y_min:y_max, x_min:x_max]\n",
        "            img = rotateImage(img)\n",
        "            detect_char = character_recognition(img)\n",
        "            table = detect_char.pandas().xyxy[0].to_numpy()\n",
        "            if len(table) == 8 or len(table) == 9 :\n",
        "              boundingBoxes = sorted(table, key=functools.cmp_to_key(compare) )\n",
        "              character = [i[6] for i in boundingBoxes]\n",
        "              character = ''.join(character)\n",
        "              cv2.rectangle(frame, (x_min, y_min), (x_max,y_max), (255,0,0), 2)\n",
        "              cv2.putText(frame, character, (x_min, y_min), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 3)\n",
        "\n",
        "  out.write(frame)\n",
        "  if cv2.waitKey(1) == ord('q'):\n",
        "    break\n",
        "\n",
        "cap.release()\n",
        "out.close()\n",
        "cv2.destroyAllWindows()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
